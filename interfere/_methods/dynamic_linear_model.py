from typing import Optional

import numpy as np
from scipy.stats import multivariate_t

from ..base import DEFAULT_RANGE, ForecastMethod


class DLM(ForecastMethod):

    def __init__(
        self,
        beta: float = 0.99,
        delta: float = 0.99,
        m0: Optional[np.ndarray] = None,
        c0: float = 100,
        Sigma: Optional[np.ndarray] = None,
        n0: int = 20,
        D0: Optional[np.ndarray] = None,
        nsamps: int = 100,
    ):
        """Initializes a Multivariate Dynamic Linear Model (MVDLM) using a
        Normal-Inverse-Wishart prior and discount factors.

        NOTE: Some of this documentation was generated by ChatGPT o1. It should be mostly correct but users should double check sources for errors.

        This model uses two discount factors: `beta` for stochastic volatility
        and `delta` for state evolution. The prior on the parameters is 
        specified via a Normal-Inverse-Wishart (NIW) distribution,
        characterized by (m0, c0, n0, D0).

        Args:
            beta (float): Stochastic volatility discount factor (0 < beta ≤ 1).
                Controls how quickly the observation/measurement covariance
                (volatility) is updated over time. Values close to 1 result in
                slower changes, while smaller values adapt more quickly.
            delta (float): State space discount factor (0 < delta ≤ 1).
                Controls how quickly the model updates/forgets past information
                about the latent state. Values close to 1 weight past data more
                strongly; smaller values adapt more quickly to new information.
            m0 (array-like of shape (k,) or None, optional): Prior mean of the
                state vector. If None, will be set to the mean of the training
                data. In the NIW prior, this corresponds to the mean vector m
                of θ.
            c0 (float, optional): Scalar scaling factor for the covariance of
                the prior on the state parameters in the NIW. Default is 100.
                In the NIW parameterization, θ | Σ ~ MVN(m, c Σ). Hence, c0
                influences how large the prior variance of θ is relative to Σ.
            Sigma (ndarray of shape (k, k)): The covariance of the prior on
                state parameters in the NIW parameterization. Defaults to the
                identity.
            n0 (int, optional): Prior degrees of freedom for the
                Inverse-Wishart distribution on Σ (must be ≥ q + 2). Default is
                20. In the NIW parameterization, Σ ~ IW(n, D), so n0
                corresponds to n.
            D0 (array-like of shape (q, q) or None, optional): Scale matrix for
                the Inverse-Wishart prior on Σ. Must be positive definite.
                Default is None, in which case a default (a scaled identity)
                is used. In the NIW parameterization, the expected value of
                Σ is D / (n - 2).
            nsamps (int, optional): Number of samples to draw from the
                posterior distribution when making predictions. Default is 100.

        Notes:
            - The NIW prior is parameterized as:
                1) θ | Σ ~ MVN(m, c Σ)
                2) Σ ~ IW(n, D)
              which implies E[Σ] = D / (n - 2) and θ marginally follows a T
              distribution: θ ~ T_n(m, c * S) where S = D / n.
            - The `beta` discount factor typically updates the observation
              covariance, while the `delta` discount factor updates the state
              evolution covariance.
            - Choose `m0`, `c0`, `n0`, and `D0` to encode domain-specific
              beliefs or ensure proper scale and variability in the prior.

        """
        self.beta = beta
        self.delta = delta
        self.m0 = m0
        self.c0 = c0
        self.Sigma = Sigma
        self.n0 = n0
        self.D0 = D0
        self.nsamps = nsamps
        self.mvdlm = None
        self.timestep = None
        self.n_states = None
        self.n_exog = None


    def _fit(
        self,
        t: np.ndarray,
        endog_states: np.ndarray,
        exog_states: np.ndarray = None,
    ):
        """Fits the method using the passed data.

        Args:
            t (ndarray): An array of time points with shape (m,).
            endog_states (ndarray): An array of endogenous signals with shape
                (m, n). Rows are  observations and columns are variables. Each
                row corresponds to the times in `t`.
            exog_states (ndarray): An array of exogenous signals with shape
                (m, k). Rows are observations and columns are variables. Each
                row corresponds to the times in `t`.
        """
        self.timestep = t[1] - t[0]

        # Check for equally spaced time points
        if not np.allclose(np.diff(t), self.timestep):
            raise ValueError("Time points must be equally spaced.")

        m0 = None
        if self.m0 is None:
            m0 = np.mean(endog_states, axis=0)


        self.n_states = endog_states.shape[1]
        if exog_states is None:
            self.n_exog = None
            # Dynamic linear model without exogenous.
            self.mvdlm = MVDLM(
                self.beta,
                self.delta,
                self.n_states,
                m0,
                self.c0,
                self.n0,
                self.D0
            )

            for i in range(endog_states.shape[0]):
                self.mvdlm.add_data(endog_states[i, :])

        else:
            self.n_exog = exog_states.shape[1]
            # Dynamic linear model with exogenous.
            self.mvdlm = MVDLM_X(
                self.beta,
                self.delta,
                self.n_states,
                self.n_exog,
                self.m0,
                self.c0,
                self.n0,
                self.D0
            )

            for i in range(endog_states.shape[0]):
                self.mvdlm.add_data(endog_states[i, :], exog_states[i, :])


    def _predict(
        self,
        t: np.ndarray,
        prior_endog_states: np.ndarray,
        prior_exog_states: Optional[np.ndarray] = None,
        prior_t: Optional[np.ndarray] = None,
        prediction_exog: Optional[np.ndarray] = None,
        rng: np.random.RandomState = DEFAULT_RANGE,
    ) -> np.ndarray:
        """Runs a simulation of the dynamics of a fitted forcasting method.

       Note: Must call `self.fit(...)` before calling `self.predict`.

        Args:
            t (ndarray): An array of the time points with shape (m,) for the
                method to simulate.
            prior_endog_states (ndarray): Aa array of historic observations of
                the n endogeneous signals with shape (p, n). Rows represent
                observations and columns represent variables This is used as the
                initial condition data or time lag information. It is not
                used to fit the method. IMPORTANT: It is assumed that the last
                row in this array was observed at time `t[0]`.
            prior_exog_states: An optional array of historic observations of the
                k exogenous signals with shape (p, k). Rows contain observations
                and columns contain variables. This is used for the
                initial condition data and lag information. It is NOT used to
                fit the method. IMPORTANT: It is assumed that the last
                row in this array was observed at time `t[0]`.
            prior_t (ndarray): An optional array with shape (p,) of times
                corresponding to the rows of `prior_endog_states` and `prior_exog_states`. If `prior_t` is not provided and `t`
                contains equally spaced points, then `prior_t` is assumed
                to contain occured at equally spaced points prior to `t`
            prediction_exog: An optional (m, k) array of exogenous signals
                corresponding to the times in `t`. Rows are observations and
                columns are variables.
            prediction_max: A threshold for predicted endogeneous values
                to prevent overflow in predictions. All predictions larger in
                magnitude will be set equal to `prediction_max`.
            rng: An optional numpy random state for reproducibility. (Uses
                numpy's mtrand random number generator by default.)

        Returns:
            X_sim: A (m, n) array of containing a multivariate time series. The
            rows are observations correstponding to entries in `time_points` and
            the columns correspod to the endogenous variables in the forecasting
            method.

        Notes:
            When `prior_t` is provided it is assumed that the rows of
            `prior_endog_states` and `prior_exog_states` were observed at the
            times contained in `prior_t`.If `prior_t` is not provided and `t`
            contains equally spaced points, then `prior_endog_states` and
            `prior_exog_states` are assumed to have occured at equally spaced
            times before `t[0]`. Additionally, the last rows of
            `prior_endog_states` and `prior_exog_states` must be an observation
            that  occured at the time `t[0]`.
        """
        # Check that time steps are equally spaced and are the same as in fit().
        if not np.allclose(np.diff(t), self.timestep):
            raise ValueError((
                "Time points must be equally spaced and match the timestep "
                "from fit()"
                "\n\t self.timestep = {self.timestep}"
            ))

        # Check that the number of enogenous and exogenous states match the ones
        # passed to fit().
        if prior_endog_states.shape[1] != self.n_states:
            raise ValueError((
                "Endogeneous state dimension is different from "
                f"fit(): \n\tFitted endo dim = {self.n_states}"
                f"\n\tPassed endo dim = {prior_endog_states.shape[1]}"
            ))

        if prediction_exog is not None and (prediction_exog.shape[1] != self.n_exog):
            raise ValueError((
                "Exogenous state dimension is different from "
                f"fit(): \n\tFitted exog dim = {self.n_exog}"
                f"\n\tPassed exog dim = {prediction_exog.shape[1]}"
            ))

        if prediction_exog is None and (self.n_exog is not None):
            raise ValueError(
                "Expected exogenous data but receieved `prediction_exog = None`."
            )

        if self.n_exog is not None:
            # When model expects exogenous:
            for i in range(len(prior_t)):
                self.mvdlm.add_data(
                    prior_endog_states[i, :],
                    prior_exog_states[i, :]
                )
            samps = self.mvdlm.forecast_path(
                prediction_exog[1:, :],
                k=len(t) - 1,
                nsamps=self.nsamps,
                rng=rng
            )

        else:
            # When model is endog only:
            for i in range(len(prior_t)):
                self.mvdlm.add_data(
                    prior_endog_states[i, :],
                )
            samps = self.mvdlm.forecast_path(
                k=len(t) - 1, nsamps=self.nsamps, rng=rng)

        X_sim = np.mean(samps, axis=2)

        # Make sure initial condition is correct.
        X_sim = np.vstack([prior_endog_states[-1, :], X_sim])

        return X_sim


    def _get_optuna_params(trial, max_lags=None) -> dict[str, object]:
        return {
            "beta": trial.suggest_float("beta", 0.1, 1.0),
            "delta": trial.suggest_float("delta", 0.1, 1.0),
            "c0": trial.suggest_float("c0", 10, 300),
            "n0": trial.suggest_int("n0", 15, 100),
        }

    def get_test_params():
        return {"nsamps": 200, "c0": 100, "delta": 0.5}

    def get_window_size(self):
        return 2


#########################################################################
# Remainder of this file taken from
# https://github.com/g-tierney/mvdlm_synth/blob/985832230318adc5ad50a87d80df522062a72109/mvdlm/MVDLM.py
#
# CODE EDITED Jan 20, 2025 by @djpasseyjr to include random state for
# reproducibility.
#
# CODE EDITED Jan 21, 2025 by @djpasseyjr to speed up prediction.
#########################################################################


# MVDLM without covariates.
class MVDLM:

    def __init__(self, beta, delta, q, m0=None, c0=100, n0=20, D0=None):
        """
        :param beta: Stochastic volitility discount factor
        :param delta: State space discount factor
        :param q: Dimension of series
        :param m0: prior mean
        :param c0: prior

        theta ~ NIW(m,c,n,D) such that:
            1) theta|Sigma ~ MVN(m,c Sigma)
            2) Sigma ~ IW(n,D) such that E[Sigma] = D/(n-2)
            3) theta ~ T_n(m,c S) where S = D/n
        """
        if m0 is None: m0=np.zeros(q)
        if D0 is None: D0=n0*np.eye(q)
        self.beta = beta
        self.delta = delta
        self.q = q
        self.m = m0
        self.m_store = []
        self.D = D0
        self.D_store = []
        self.c = c0
        self.c_store = []

        self.n = n0 #self.h-self.q+1
        self.n_store = []
        self.h = self.n + self.q - 1
        self.h_store = []
        self.t = 0
        self.y = None

        self.G = np.eye(q)

    def add_data(self, y):
        e = y-self.m
        r = self.c/self.delta
        q_t = r + 1
        A = r/q_t
        self.m = (self.m + A*e)
        self.m_store.append(self.m)
        self.c = r - (A**2)*q_t
        self.c_store.append(self.c)
        self.D = self.beta*self.D + np.reshape(e, (self.q,1)) @ np.reshape(e, (1,self.q))/q_t
        self.D_store.append(self.D)

        self.h = self.beta*self.h + 1
        self.h_store.append(self.h)

        self.n = self.h-self.q + 1
        self.n_store.append(self.n)

        self.t = self.t +1
        if self.y is None:
            self.y = y
        else:
            self.y = np.row_stack([self.y, y])

        #if set_w: self.set_w()

    def get_forecast_params(self):
        """Returns all parameters needed for forecasting.
        """
        return {
            "m": self.m,
            "c": self.c,
            "h": self.h,
            "n": self.n,
            "D": self.D,
        }


    def set_forecast_params(
        self,
        m=None,
        c=None,
        h=None,
        n=None,
        D=None,
    ):
        """Sets all parameters needed for forecasting.
        """
        self.m = m
        self.c = c
        self.h = h
        self.n = n
        self.D = D


    def forecast_marginal(
        self,
        k=1,
        nsamps=1,
        params_only=False,
        mean_only=False,
        rng=DEFAULT_RANGE
    ):
        #Gk = np.linalg.matrix_power(self.G,k)
        a = self.m
        r = self.c/self.delta
        q_t = r + 1

        df = self.beta*self.h - self.q + 1
        S = self.D/self.n
        S = (S + S.T)/2

        if mean_only:
            return a
        elif params_only:
            return a,q_t,df,S
        else:
            samples = np.zeros((nsamps,self.q))

            rv = multivariate_t(a,q_t*S,df)
            return rv.rvs(size=nsamps, random_state=rng)

    def forecast_path(self,k=1,nsamps=1, rng=DEFAULT_RANGE):

        samps = np.zeros((k,self.q,nsamps))
        for i in range(nsamps):
            # Make a copy of the current model.
            mvdlm_copy = MVDLM(self.beta, self.delta, self.q)
            mvdlm_copy.set_forecast_params(**self.get_forecast_params())

            # Make a recurive forecast.
            for t in range(k):
                ysim = mvdlm_copy.forecast_marginal(k=1, rng=rng)
                mvdlm_copy.add_data(ysim)

                samps[t,:,i] = ysim

        return samps

# MVDLM with covariates (X)
class MVDLM_X:

    def __init__(self, beta, delta, q, p, m0=None, c0=None, n0 = 20, D0 = None):

        self.beta = beta
        self.delta = delta
        self.q = q #y dimension
        self.p = p #X dimension
        self.n = n0
        self.h = self.n + self.q - 1

        if m0 is None: m0 = np.zeros((self.p,self.q))
        if c0 is None: c0 = 1
        if D0 is None: D0 = np.eye(self.q)*self.n

        self.M = m0
        self.C = c0 * np.eye(self.p)
        self.D = D0

        self.F = np.empty((self.p,1))

        self.t = 0

        self.M_store = [self.M]
        self.C_store = [self.C]
        self.D_store = [self.D]
        self.h_store = [self.h]
        self.n_store = [self.n]


    def add_data(self,y,x):

        #collect values
        self.F = np.reshape(x,(self.p,1))
        self.y = np.reshape(y,(self.q,1))

        #evolve posterior to prior
        self.R = self.C/self.delta

        #collect errors
        self.f = self.M.T @ self.F
        e = self.y - self.f
        self.q_t = (self.F.T @ self.R @ self.F) + 1
        A = self.R @ self.F / self.q_t

        #update
        self.M = self.M + A @ e.T
        self.C = self.R - A @ A.T * self.q_t
        self.h = self.beta*self.h + 1
        self.n = self.h - self.q + 1
        self.D = self.beta * self.D + e @ e.T / self.q_t

        self.t = self.t + 1

        #store results
        self.M_store.append(self.M)
        self.C_store.append(self.C)
        self.D_store.append(self.D)
        self.h_store.append(self.h)
        self.n_store.append(self.n)


    def get_forecast_params(self):
        """Returns all parameters needed for forecasting.
        """
        return {
            "C": self.C,
            "M": self.M,
            "h": self.h,
            "n": self.n,
            "D": self.D,
        }


    def set_forecast_params(
        self,
        C=None,
        M=None,
        h=None,
        n=None,
        D=None,
    ):
        """Sets all parameters needed for forecasting.
        """
        self.C = C
        self.M = M
        self.h = h
        self.n = n
        self.D = D


    def forecast_marginal(self,x,k=1,nsamps=1,Y=None,params_only=False,mean_only=False,log_likelihood=False, rng=DEFAULT_RANGE):

        #collect values
        F = np.reshape(x,(self.p,1))
        R = self.C/self.delta

        f = self.M.T @ F
        q_t = (F.T @ R @ F) + 1

        df = self.beta*self.h - self.q + 1
        S = self.D/self.n
        S = (S + S.T)/2

        if mean_only:
            return f
        elif params_only:
            return f, q_t, df, S
        elif log_likelihood:
          rv = multivariate_t(f.reshape((self.q,)),q_t*S,df)
          return rv.logpdf(Y)
        else:

            rv = multivariate_t(f.reshape((self.q,)),q_t*S,df)
            return rv.rvs(size=nsamps, random_state=rng)

    def forecast_path(self,x,k=1,nsamps=1, rng=DEFAULT_RANGE):
        x = np.reshape(x,(k,self.p))

        samps = np.zeros((k,self.q,nsamps))
        for i in range(nsamps):
            mvdlm_x_copy = MVDLM_X(self.beta, self.delta, self.q, self.p)
            mvdlm_x_copy.set_forecast_params(**self.get_forecast_params())
            for t in range(k):
                ysim = mvdlm_x_copy.forecast_marginal(
                    x=x[t,:],k=1,nsamps=1, rng=rng)
                mvdlm_x_copy.add_data(ysim,x[t,:])

                samps[t,:,i] = ysim

        return samps